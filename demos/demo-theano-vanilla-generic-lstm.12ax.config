#!returnn.py
# kate: syntax python;

import os
demo_name, _ = os.path.splitext(__file__)
print("Hello, experiment: %s" % demo_name)

task = "train"
train = {"class": "Task12AXDataset", "num_seqs": 1000}
dev = {"class": "Task12AXDataset", "num_seqs": 100, "fixed_random_seed": 1}

num_inputs = 9
num_outputs = 2
batching = "random"
batch_size = 5000
max_seqs = 10
chunking = "200:200"

network = {
"fw0": {"class": "generic_lstm", "n_out": 10,
	# As input, we get the 9dim real input + 10dim recurrent previous out.
	# As output, we want 4 * n_cells.
	"sublayer": {"class": "hidden", "activation": "identity"}
},
"output": {"class": "softmax", "loss": "ce", "from": ["fw0"]}
}

# training
adam = True
learning_rate = 0.01
model = "/tmp/returnn.%s.network" % demo_name
num_epochs = 100
save_interval = 20
gradient_clip = 0

# log
log_verbosity = 4

