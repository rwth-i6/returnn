#!returnn.py
# kate: syntax python;
# -*- mode: python -*-
# sublime: syntax 'Packages/Python Improved/PythonImproved.tmLanguage'
# vim:set expandtab tabstop=4 fenc=utf-8 ff=unix ft=python:

import os
from returnn.tensor import Tensor, Dim, batch_dim
import returnn.frontend as rf
from returnn.util.basic import get_login_username

demo_name, _ = os.path.splitext(__file__)
print("Hello, experiment: %s" % demo_name)

backend = "torch"

task = "train"
train = {"class": "Task12AXDataset", "num_seqs": 1000}
dev = {"class": "Task12AXDataset", "num_seqs": 100, "fixed_random_seed": 1}

time_dim = Dim(None, name="time")
in_dim = Dim(9, name="in")
out_dim = Dim(2, name="out")
extern_data = {
    "data": {"dims": (batch_dim, time_dim, in_dim), "dtype": "float32"},
    "classes": {"dims": (batch_dim, time_dim), "sparse_dim": out_dim, "dtype": "int32"},
}

batching = "random"
batch_size = 5000
max_seqs = 10

class Model(rf.Module):
    def __init__(self):
        super().__init__()
        self.layer1 = rf.Linear(in_dim, Dim(50, name="hidden"))
        self.layer2 = rf.Linear(self.layer1.out_dim, Dim(100, name="hidden2"))
        self.layer3 = rf.Linear(self.layer2.out_dim, out_dim)

    def __call__(self, x: Tensor):
        x = rf.relu(self.layer1(x))
        x = rf.relu(self.layer2(x))
        x = self.layer3(x)
        return x  # logits

def get_model(**_kwargs):
    return Model()

def train_step(*, model: Model, extern_data, **_kwargs):
    data = extern_data["data"]
    logits = model(data)
    logits_packed, pack_dim = rf.pack(logits, dims=(batch_dim, time_dim), enforce_sorted=False)
    targets = extern_data["classes"]
    targets_packed, _ = rf.pack(targets, dims=(batch_dim, time_dim), enforce_sorted=False, out_dim=pack_dim)
    loss = rf.cross_entropy(estimated=logits_packed, estimated_type="logits", target=targets_packed, axis=out_dim)
    loss.mark_as_loss(name="ce")


# training
optimizer = {"class": "adam"}

learning_rate = 0.01
learning_rate_control = "newbob"
learning_rate_decay = 0.9
newbob_relative_error_threshold = 0.0
learning_rate_file = "/tmp/%s/returnn/%s/learning_rates" % (get_login_username(), demo_name)

model = "/tmp/%s/returnn/%s/model" % (get_login_username(), demo_name)
num_epochs = 5

# log
#log_verbosity = 3
log_verbosity = 5
