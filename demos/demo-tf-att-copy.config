#!returnn/rnn.py
# kate: syntax python;

import os
from returnn.util.basic import get_login_username
demo_name, _ = os.path.splitext(__file__)
print("Hello, experiment: %s" % demo_name)

# task
use_tensorflow = True
task = "train"

# data
num_inputs = 10
num_outputs = {"data": [num_inputs,1], "classes": [num_inputs,1]}
train = {"class": "CopyTaskDataset", "nsymbols": num_inputs, "num_seqs": 1000, "minlen": 1, "maxlen_epoch_factor": 20}
dev = {"class": "CopyTaskDataset", "nsymbols": num_inputs, "num_seqs": 50, "minlen": 1, "maxlen_epoch_factor": 20}

batch_size = 5000
max_seqs = 10
chunking = "0"

_isize = 5
l2 = 0.01

network = {
    "input": {"class": "linear", "activation": "tanh", "n_out": 20},

    "decoder": {"class": "rec", "from": [], "size_target": "classes", "unit": {
        # "dt": {"class": "constant", "value": 1.0, "from": []},  # that trivially learns 0% FER
        "dt_in": {"class": "linear", "activation": "tanh", "n_out": 20, "from": ["prev:output", "prev:att_comb", "prev:dt"], "L2": l2},
        "dt": {"class": "linear", "activation": "2*sigmoid", "n_out": 1, "from": ["dt_in"], "L2": l2},
        "t": {"class": "combine", "kind": "add", "n_out": 1, "from": ["prev:t", "dt"], "initial_output": -1, "L2": l2},
        "att": {"class": "gauss_window_attention", "window_size": 10, "inner_size": _isize, "from": ["t"], "base": "base:input"},  # shape: (batch,_isize,input.n_out)
        "att_comb": {"class": "combine_dims", "axes": "static", "from": ["att"]},  # shape: (batch,input.n_out * _isize)
        "output": {"class": "linear", "activation": "tanh", "from": ["att_comb"], "n_out": 20, "L2": l2}
    }},

    "output": {"class": "softmax", "from": ["decoder"], "loss": "ce", "grad_filter": 1.0}
}

optimizer = {"class": "adam"}
learning_rate = 0.01
gradient_noise = 0.3
gradient_clip = 2
# Note that this behavior here is slightly off because the cross-validation dev-set will get harder in each epoch.
use_last_best_model = {"modulo": 5, "filter_score": 1.5, "only_last_n": 5, "min_score_dist": 0.2}
model = "/tmp/%s/returnn/%s/model" % (get_login_username(), demo_name)  # https://github.com/tensorflow/tensorflow/issues/6537
num_epochs = 100
log_verbosity = 4

# epoch 24 score: 0.338749137324 elapsed: 0:01:33 dev: score 1.81706249405 error 0.161244292237
# Last epoch 24 (score: 1.817062) is not the optimal model but epoch 20 has better score 0.020426 ({'dev_score': 0.020425787440570525, 'train_score': 0.27955507594920537, 'dev_error': 0.0065372424722662439}), will use that model.
# epoch 25 score: 0.653981911886 elapsed: 0:01:39 dev: score 0.0244906892198 error 0.00699665053964
# epoch 26 score: 1.02113737811 elapsed: 0:02:01 dev: score 0.0614190819807 error 0.0117162249515
# epoch 27 score: 0.0996640938671 elapsed: 0:02:12 dev: score 0.024542749341 error 0.00657429662095
# epoch 28 score: 0.0460736831976 elapsed: 0:02:13 dev: score 0.0189841117783 error 0.00589081443935
# ...
# epoch 36 score: 0.934458460298 elapsed: 0:03:11 dev: score 0.0174642789072 error 0.00573016148637
# ...
# epoch 45 score: 0.605543253181 elapsed: 0:09:41 dev: score 0.015333798452 error 0.00562687790221
# ...
