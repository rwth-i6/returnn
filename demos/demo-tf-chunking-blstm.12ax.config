#!returnn.py
# kate: syntax python;

use_tensorflow = True

import os
from returnn.util.basic import get_login_username
demo_name, _ = os.path.splitext(__file__)
print ("Hello, experiment: %s" % demo_name)

task = "train"
train = {"class": "Task12AXDataset", "num_seqs": 1000}
dev = {"class": "Task12AXDataset", "num_seqs": 100, "fixed_random_seed": 1}

num_inputs = 9
num_outputs = 2
batching = "random"
batch_size = 5000
max_seqs = 10

network = {
"in": {"class": "time_chunking", "chunk_size": 22, "chunk_step": 11, "from": "data"},

"fw0": {"class": "rec", "unit": "BasicLSTM", "n_out": 10, "from": "in"},
"bw0": {"class": "rec", "unit": "BasicLSTM", "n_out": 10, "from": "in"},
"fw1": {"class": "rec", "unit": "BasicLSTM", "n_out": 10, "from": ["fw0", "bw0"]},
"bw1": {"class": "rec", "unit": "BasicLSTM", "n_out": 10, "from": ["fw0", "bw0"]},
"fw2": {"class": "rec", "unit": "BasicLSTM", "n_out": 10, "from": ["fw1", "bw1"]},
"bw2": {"class": "rec", "unit": "BasicLSTM", "n_out": 10, "from": ["fw1", "bw1"]},

"out": {"class": "time_unchunking", "chunking_layer": "in", "from": ["fw2", "bw2"]},

"output": {"class": "softmax", "loss": "ce", "from": "out"}
}

# training
optimizer = {"class": "adam"}
learning_rate = 0.01
model = "/tmp/%s/returnn/%s/model" % (get_login_username(), demo_name)  # https://github.com/tensorflow/tensorflow/issues/6537
num_epochs = 100
save_interval = 1
gradient_clip = 0

# log
log_verbosity = 5
tf_log_memory_usage = True
log_batch_size = True
