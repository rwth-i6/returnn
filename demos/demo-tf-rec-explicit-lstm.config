#!returnn/rnn.py
# kate: syntax python;

import os
from returnn.util.basic import get_login_username
demo_name, _ = os.path.splitext(__file__)
print("Hello, experiment: %s" % demo_name)

# task
use_tensorflow = True
task = "train"

# data
train = {"class": "Task12AXDataset", "num_seqs": 1000}
num_inputs = 9
num_outputs = 2

dev = train.copy()
dev.update({"num_seqs": train["num_seqs"] // 10, "fixed_random_seed": 42})

# network
# (also defined by num_inputs & num_outputs)
network = {
    "lstm": {"class": "rec", "from": "data", "unit": {
        "input": {"class": "copy", "from": ["prev:output", "data:source"]},
        "input_gate": {"class": "linear", "from": "input", "activation": "sigmoid", "n_out": 10},
        "forget_gate": {"class": "linear", "from": "input", "activation": "sigmoid", "n_out": 10},
        "output_gate": {"class": "linear", "from": "input", "activation": "sigmoid", "n_out": 10},
        "cell_in": {"class": "linear", "from": "input", "activation": "tanh", "n_out": 10},
        "c": {"class": "eval", "from": ["input_gate", "cell_in", "forget_gate", "prev:c"],
            "eval": "source(0) * source(1) + source(2) * source(3)"},
        "output": {"class": "eval", "from": ["output_gate", "c"],
            "eval": "source(0) * source(1)"},
    }},
    "output": {"class": "softmax", "loss": "ce", "from": "lstm"}
}

debug_print_layer_output_template = True

# trainer
batching = "random"
batch_size = 5000
max_seqs = 40
chunking = "0"
optimizer = {"class": "adam"}
gradient_noise = 0.3
learning_rate = 0.01
learning_rate_control = "newbob"
learning_rate_control_relative_error_relative_lr = True
model = "/tmp/%s/returnn/%s/model" % (get_login_username(), demo_name)  # https://github.com/tensorflow/tensorflow/issues/6537
num_epochs = 100
save_interval = 20

# log
log_verbosity = 5

