#!/usr/bin/env ../rnn.py
# kate: syntax python;
# -*- mode: python -*-
# sublime: syntax 'Packages/Python Improved/PythonImproved.tmLanguage'
# vim:set expandtab tabstop=4 fenc=utf-8 ff=unix ft=python:

# Also see demo-tf-att-copy.config for a soft attention variant of the same task.

# network topology based on:
# https://github.com/rwth-i6/returnn-experiments/blob/master/2019-librispeech-system/attention/base2.bs18k.curric3.config
# adapted/simplified/extended for hard attention

# Methods:
# * First soft-attention + hard-attention, then hard-attention only.
# * Initially, output label cross-entropy for all beams.
# * Add EOS to target.
# * Add EOS to source.
# * Convolution on encoder context, such that shifted related context can be used.
# * Given current decoder position, trainable encodings for next few frames.

# Results:
# pretrain epoch 11 score: alignment_frame_error 5.81742604097684e-10 decide 3.0660502359228293e-09 error: alignment_edit_dist 0.0 alignment_frame_error 0.0 output_edit_dist 0.0 elapsed: 0:00:19
# dev: score alignment_frame_error 5.797026978627638e-06 decide 5.7970186185525265e-06 error alignment_edit_dist 0.0 alignment_frame_error 0.0 output_edit_dist 0.0

import os
from pprint import pprint
from returnn.util.basic import get_login_username
demo_name, _ = os.path.splitext(__file__)
print("Hello, experiment: %s" % demo_name)
config = globals()["config"]  # make PyCharm happy

# task
use_tensorflow = True
task = config.value("task", "train")

if task == "train":
  beam_size = 4
else:
  beam_size = 12

# data
num_inputs = 10
num_outputs = {"data": [num_inputs,1], "classes": [num_inputs,1]}
train = {"class": "CopyTaskDataset", "nsymbols": num_inputs, "num_seqs": 10000, "minlen": 5, "maxlen": 5}
#dev = {"class": "CopyTaskDataset", "nsymbols": num_inputs, "num_seqs": 50, "minlen": 1, "maxlen": 20, "fixed_random_seed": 42}
dev = {"class": "CopyTaskDataset", "nsymbols": num_inputs, "num_seqs": 50,
       "minlen": 20, "maxlen": 20,  # "maxlen_epoch_factor": 5,
       "fixed_random_seed": 42}

batch_size = 5000
max_seqs = 10


EncKeyTotalDim = 20
EncValueTotalDim = 20
target = "classes"


def rel_embed(self, source, **kwargs):
  import tensorflow as tf
  from returnn.tf.util.basic import nd_indices
  x = source(0, as_data=True, auto_convert=False)  # (B, T, K)
  v = source(1, as_data=True, auto_convert=False)  # (B, Ts, K)
  assert v.dim == x.dim
  t = source(2, auto_convert=False)  # (B,)
  t = t + 1  # shift by 1, because we init at -1
  #t = tf.Print(t, ["t:", t])
  time_dim = tf.shape(x.placeholder)[x.time_dim_axis]
  batch_dim = tf.shape(x.placeholder)[x.batch_dim_axis]
  assert len(v.shape) == 2 and all([isinstance(d, int) for d in v.shape])
  ts_dim = v.shape[0]
  indices = tf.expand_dims(tf.range(ts_dim), axis=0)  # (1,Ts)
  indices = indices + tf.expand_dims(t, axis=1)  # (B,Ts)
  max_t = tf.maximum(tf.reduce_max(indices) + 1, time_dim + 1)
  indices = nd_indices(indices)  # (B,Ts,2)
  x0 = tf.scatter_nd(
    indices=indices, updates=v.placeholder, shape=[batch_dim, max_t, x.dim])  # (B,T,K)
  x0 = x0[:, 1:time_dim + 1]  # correct the shift from above
  assert x.batch_dim_axis == v.batch_dim_axis == 0
  out = x.placeholder + x0
  #out = tf.Print(out, ["i:", network.get_rec_step_index(), "t:", t], summarize=5)
  return out


def loss_ce(source, **kwargs):
  import tensorflow as tf
  from returnn.tf.util.basic import nd_indices, safe_log
  x = source(0, auto_convert=False, as_data=True).copy_as_batch_major()
  y = source(1, auto_convert=False, as_data=True).copy_as_batch_major()
  assert y.batch_ndim == 1 and x.batch_ndim == y.batch_ndim + 1 and x.dim == y.dim
  x_ = safe_log(x.placeholder)
  assert x_.op.type != "Log"  # it means we used LogSoftmax or so
  out = -tf.gather_nd(x_, nd_indices(y.placeholder))
  #out = tf.Print(out, [x.name, "loss", out, "shape", tf.shape(out)])
  return out


def combine_soft_hard_att(self, source, **kwargs):
  # source(0) is hard att, source(1) is soft att
  pretrain_idx = self.network.parent_net.layers_desc["#pretrain_idx"]
  print("combine_soft_hard_att, pretrain idx %r" % pretrain_idx)
  if pretrain_idx is not None and pretrain_idx <= 1:
    frac = 0.5
    return source(0) * frac + source(1) * (1. - frac)
  else:
    source(1)  # call, but ignore
    return source(0)  # only hard att


def t_cheat_target(source, **kwargs):
  # For this task, we now the correct `t` value for each decoder step, which is just an exact linear segmentation.
  import tensorflow as tf
  from returnn.tf.util.basic import expand_dims_unbroadcast
  data = source(0, as_data=True, auto_convert=False)
  time_dim = tf.shape(data.placeholder)[data.time_dim_axis]
  batch_dim = tf.shape(data.placeholder)[data.batch_dim_axis]
  targets = tf.range(time_dim)  # (T,)
  targets = expand_dims_unbroadcast(targets, axis=data.batch_dim_axis, dim=batch_dim)  # (B,T)
  return targets


network = {
  "#pretrain_idx": None,

  "data_with_eos_": {"class": "reinterpret_data", "from": "data", "increase_sparse_dim": 1},
  "data_with_eos": {"class": "postfix_in_time", "postfix": num_inputs, "from": "data_with_eos_"},
  "input": {"class": "linear", "from": "data_with_eos", "activation": "tanh", "n_out": 20},

  "encoder": {"class": "copy", "from": "input"},  # dim: EncValueTotalDim
  "enc_ctx": {"class": "conv", "filter_size": [3], "padding": "same",
              "activation": None, "with_bias": True, "from": "encoder",
              "n_out": EncKeyTotalDim},  # (B, enc-T, D)
  "enc_value": {"class": "copy", "from": "encoder"},  # (B, enc-T, D)

  "output": {"class": "rec", "from": [], 'only_on_search': True, 'cheating': config.bool("cheating", False), "unit": {
    "s_transformed": {"class": "linear", "activation": None, "with_bias": False, "from": "s", "n_out": EncKeyTotalDim},
    "t_rel_var": {"class": "variable", "shape": (3, EncKeyTotalDim)},
    "energy_in": {"class": "combine", "kind": "add", "from": ["base:enc_ctx", "s_transformed"], "n_out": EncKeyTotalDim},
    "energy_in1": {
        "class": "eval", "from": ["energy_in", "t_rel_var", "prev:t"], "eval": rel_embed,
        "out_type": lambda sources, **kwargs: sources[0].output},
    "energy_tanh": {"class": "activation", "activation": "tanh", "from": "energy_in1"},
    "energy": {"class": "linear", "activation": None, "with_bias": False, "from": "energy_tanh", "n_out": 1},  # (B, enc-T, 1)
    "energy0": {"class": "squeeze", "axis": "f", "from": "energy"},  # (B, enc-T)
    "att_weights": {"class": "softmax_over_spatial", "from": "energy0", "start": "prev:t"},  # (B, enc-T)
    # ChoiceLayer works on the feature axis.
    "att_weights0": {"class": "reinterpret_data", "from": "att_weights", "set_axes": {"f": "t"},
                     "is_output_layer": True},

    "t": {
        "class": "choice", "from": "att_weights0", "target": None, "beam_size": beam_size,
        #"base_beam_score_scale": 0.0 if task == "train" else 1.0,  # later remove...
        #"random_sample_scale": 1.0 if task == "train" else 0.0,  # later remove...
        "length_normalization": False, "initial_output": -1},  # (B,)
    #"t": {"class": "print", "from": "t0", "initial_output": 0},
    # collocate_with to have it with the current beam
    #"t_ce": {
    #    "class": "eval", "from": ["att_weights0", "t"], "eval": loss_ce,
    #    "loss": "as_is", "collocate_with": "t",
    #    "out_type": {"shape": (), "feature_dim_axis": None, "time_dim_axis": None, "dtype": "float32"}},

    "att0": {"class": "gather_nd", "position": "t", "from": "base:enc_value"},  # (B, V)
    "att1": {"class": "generic_attention", "weights": "att_weights", "base": "base:enc_value"},  # (B, V)
    "att": {"class": "eval", "from": ["att0", "att1"], "eval": combine_soft_hard_att},

    "s": {"class": "rnn_cell", "unit": "LSTMBlock", "from": ["prev:target_embed", "prev:att"], "n_out": 20},
    "readout_in": {"class": "linear", "from": ["s", "prev:target_embed", "att"], "activation": None, "n_out": 50},
    "readout": {"class": "reduce_out", "mode": "max", "num_pieces": 2, "from": "readout_in"},
    "output_prob": {"class": "softmax", "from": "readout", "target": "target_with_eos"},

    'output': {
        'class': 'choice', 'target': "target_with_eos",
        'search': task != 'train', "length_normalization": task != 'train',
        # 'prob_scale': 0.0 if task == "train" else 1.0,  # remove this later if we fix training...
        'beam_size': beam_size, 'cheating': config.bool("cheating", False), 'from': "output_prob",
        "initial_output": num_inputs},
    "output_ce": {
        "class": "eval", "from": ["output_prob", "output"], "eval": loss_ce,
        # "loss": "as_is",  # only in pretrain step 1
        "collocate_with": "output",
        "out_type": {"shape": (), "feature_dim_axis": None, "time_dim_axis": None, "dtype": "float32", "dim": None}},

    "end": {"class": "compare", "from": "output", "value": num_inputs},
    'target_embed': {
      'class': 'linear', 'activation': None, "with_bias": False, 'from': 'output', "n_out": 20,
      'initial_output': 'var'},

  }, "target": ["target_with_eos", "t_cheat_target"], "max_seq_len": "max_len_from('base:encoder')"},

  # Optimize the search score.
  # Note that we might want to keep the loss to optimize and the search score separate...
  # For now, it is the same value.
  "decide": {"class": "decide", "from": "output", "loss": "search_score", "only_on_search": True},
  "output_edit_dist": {
    "class": "copy", "only_on_search": True,
    "from": "decide", "target": "target_", "loss": "edit_distance", "loss_scale": 0},

  "target_with_eos_": {
    "class": "reinterpret_data", "from": "data:%s" % target, "increase_sparse_dim": 1,
    "register_as_extern_data": "target_"},
  "target_with_eos": {
    "class": "postfix_in_time", "postfix": num_inputs, "from": "target_with_eos_",
    "register_as_extern_data": "target_with_eos"},

  "t_cheat_target": {"class": "eval", "from": "data:%s" % target, "eval": t_cheat_target,
                     "register_as_extern_data": "t_cheat_target", "out_type": {"dim": None}},

  # Cheating loss (not used for training, just reporting).
  "alignment0": {"class": "decide", "only_on_search": True, "from": "output/att_weights0"},
  "alignment": {
    "only_on_search": True, "from": "alignment0",
    "class": "copy",
    #"class": "print",
  },
  "alignment_frame_error": {
    "class": "copy", "only_on_search": True,
    "from": "alignment", "target": "t_cheat_target", "loss": "ce", "loss_scale": 0},
  "alignment_edit_dist": {
    "class": "reduce", "mode": "argmax", "axes": "f", "only_on_search": True,
    "from": "alignment",  "target": "t_cheat_target", "loss": "edit_distance", "loss_scale": 0},
}

search_train_network_layers = [
  "output", "decide", "output_edit_dist",
  "alignment_frame_error", "alignment_edit_dist"]
debug_print_layer_output_template = True


def pretrain_construct(idx, net_dict):
  """
  :param int idx:
  :param dict[str,dict[str]|int] net_dict:
  :return: new net_dict
  :rtype: dict[str,dict[str]|int]
  """
  if idx >= 2:
    return None
  net_dict["#pretrain_idx"] = idx  # enforce new construction, and provide info for eval funcs
  net_dict["#repetition"] = 5
  if idx == 0:
    net_dict["output"]["unit"]["output_ce"]["loss"] = "as_is"
  return net_dict


pretrain = {"construction_algo": pretrain_construct}

stop_on_nonfinite_train_score = False
optimizer = {"class": "adam"}
learning_rate = 0.01
#learning_rate = 0.001
model = "/tmp/%s/returnn/%s/model" % (get_login_username(), demo_name)
start_epoch = 1
num_epochs = 100
log_verbosity = 4  # 5
#log_verbosity = 5

